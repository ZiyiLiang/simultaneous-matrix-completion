{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "427783e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('../pairedRS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c34d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "import pandas as pd\n",
    "import pdb\n",
    "import sys\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f50c0abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Oct 13 09:58:12 AM: Encountered unexpected exception importing solver OSQP:\n",
      "ImportError('DLL load failed while importing qdldl: The specified module could not be found.')\n"
     ]
    }
   ],
   "source": [
    "from utils import *     # contains some useful helper functions \n",
    "from models import *    # toy models\n",
    "from solvers import *   # matrix completion solvers\n",
    "from methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66e46dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the latent weights based on the factor matrices\n",
    "class SamplingBias():\n",
    "    def __init__(self, m, n, standardize=True):\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.shape = (self.m, self.n)\n",
    "        self.std = standardize\n",
    "        \n",
    "    def latent_weights(self, U, V, v, a, b, scale=0.5):\n",
    "        r = int(len(v)/2)\n",
    "        x = np.tile(np.dot(U, v[:r]), (len(U),1)).T + np.tile(np.dot(V, v[r:]), (len(U),1))\n",
    "        w = np.zeros_like(x)\n",
    "        w[np.where((x <= b) & (x >= a))] = 1\n",
    "        w[np.where(x > b)] = scipy.stats.norm.pdf(x[np.where(x > b)], loc=b, scale=scale)/scipy.stats.norm.pdf(b, loc=b, scale=scale)\n",
    "        w[np.where(x < a)] = scipy.stats.norm.pdf(x[np.where(x < a)], loc=a, scale=scale)/scipy.stats.norm.pdf(a, loc=a, scale=scale)\n",
    "        return w/np.sum(w) if self.std else w\n",
    "\n",
    "    def unif_weights(self):\n",
    "        w = np.ones(self.shape)\n",
    "        return w/np.sum(w) if self.std else w\n",
    "\n",
    "    def inc_weights(self, scale=1):\n",
    "        w = np.arange(1, self.m*self.n+1)**scale/(self.m*self.n)\n",
    "        w = w.reshape(self.shape)\n",
    "        return w/np.sum(w) if self.std else w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefe8915",
   "metadata": {},
   "source": [
    "## Weighted model 1\n",
    "For the model outline and method details, refer to Section 5.3 in the CMC Overleaf draft.\n",
    "In this setting, we consider $w_1(I_i) = \\frac{i}{N}$ where $N$ is the total number of entries in the matrix, and $w_2(I_i)=\\frac{1}{n_{\\text{test}}}$. Roughly speaking, observations are sampled with a probability proportional to the index value and test points are uniformly sampled from the missing entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "648e86e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment parameters\n",
    "m, n, r = 200,200,10\n",
    "prop_obs = 0.5\n",
    "alpha = 0.1\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5679ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the weights\n",
    "# spatially determined weights, lower half of the indexes are more likely to\n",
    "# be observed, for instance, a database with data ranked from oldest to newest\n",
    "# and newer data are comprehensive. \n",
    "scale = 1.3\n",
    "biasmodel = SamplingBias(m,n)\n",
    "w = biasmodel.inc_weights(scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81382741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling with weight from the noiseless random factorization model... \n",
      "\n",
      "Dark spots indicating the missing entries.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RandomSampling' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSampling with weight from the noiseless random factorization model... \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDark spots indicating the missing entries.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampling\u001b[49m(m, n)\n\u001b[0;32m      7\u001b[0m obs \u001b[38;5;241m=\u001b[39m sampler\u001b[38;5;241m.\u001b[39msample_observed(prop_obs, w\u001b[38;5;241m=\u001b[39mw, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m      8\u001b[0m test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones_like(obs) \u001b[38;5;241m-\u001b[39m obs\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomSampling' is not defined"
     ]
    }
   ],
   "source": [
    "RFM = RandomFactorizationModel(m ,n, r)\n",
    "U, V, M = RFM.sample_noiseless(random_state)\n",
    "\n",
    "print('Sampling with weight from the noiseless random factorization model... \\n')\n",
    "print('Dark spots indicating the missing entries.')\n",
    "sampler = PairSampling(n1,n2)\n",
    "obs = sampler.sample_observed(prop_obs, w=w, random_state=random_state)\n",
    "mask_obs = sampler.sample_submask(size_obs, random_state=random_state)\n",
    "test = np.ones_like(obs) - obs\n",
    "train, calib = sampler.sample_train_calib(obs, calib_size=0.2*np.sum(obs), \n",
    "                                            random_state = random_state)\n",
    "assert np.sum(train+calib==obs) == m*n,'Sampling error!'\n",
    "vmin, vmax = np.min(M)-100, np.max(M)\n",
    "plot_before_after_mask(M, obs, vmin, vmax)\n",
    "print(\"Observation size: {}, training size: {}, calib size: {}\"\n",
    "      .format(np.sum(obs), np.sum(train), np.sum(calib)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116c1591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
