{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30320a16-e700-4f9e-a27e-efe00921f1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('../smc')\n",
    "sys.path.append('../third_party')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b51d281-663f-4476-afc2-bf1f3edcdffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import *     # contains some useful helper functions \n",
    "from models import *    # toy models\n",
    "from solvers import *   # matrix completion solvers\n",
    "from methods import *\n",
    "from missingness_estimation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb14887a-b24e-4a77-a18f-d756193d9418",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 8\n",
    "seed = 1\n",
    "\n",
    "# Fixed data parameters\n",
    "max_test_queries = 100            \n",
    "max_calib_queries = 2000\n",
    "matrix_generation_seed = 2024    # Data matrix is fixed \n",
    "\n",
    "n1 = n2 = 300\n",
    "\n",
    "model = \"RFM\"\n",
    "solver = \"svt\"\n",
    "r_solver = 8\n",
    "prop_obs = 0.3\n",
    "\n",
    "sd = 0.5\n",
    "\n",
    "# Other parameters\n",
    "verbose = True\n",
    "allow_inf = False\n",
    "alpha = 0.1\n",
    "\n",
    "scale=0.2\n",
    "const=1\n",
    "\n",
    "\n",
    "k_list = [5]\n",
    "repetition = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cb59e52-48c1-4186-a16c-4b1c6b861cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing the ground truth matrix generated from the RFM model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# Generate Data #\n",
    "#################\n",
    "if model == \"RFM\":\n",
    "    mm = RandomFactorizationModel(n1 ,n2, 8)\n",
    "elif model == \"ROM\":\n",
    "    mm = RandomOrthogonalModel(n1 ,n2, 8)\n",
    "else:\n",
    "    mm = RandomFactorizationModel(n1 ,n2, 8)\n",
    "\n",
    "if verbose:\n",
    "    print('Fixing the ground truth matrix generated from the {} model.\\n'.format(model))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "_, _, _, M = mm.sample_noisy(sigma=sd, random_state = matrix_generation_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c01dab40-64fb-4b30-982d-b16a6d454405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Define Experiment #\n",
    "#####################\n",
    "def run_single_experiment(M_true, k, alpha, prop_obs, max_test_queries, max_calib_queries,\n",
    "                          r, scale, random_state=0):\n",
    "    res = pd.DataFrame({})\n",
    "\n",
    "\n",
    "    #--------Observation bias-------#\n",
    "    #-------------------------------#\n",
    "    n1, n2 = M_true.shape\n",
    "    bm = SamplingBias(n1,n2, normalize=False)\n",
    "    w_obs = bm.block_weights(ratio=alpha, scale=scale, random_state=random_state)\n",
    "\n",
    "    #-------Generate masks----------#\n",
    "    #-------------------------------#\n",
    "    sampler = QuerySampling(n1,n2)\n",
    "    mask_obs, mask_test = sampler.sample_submask(sub_size=prop_obs, w=w_obs, random_state=random_state)\n",
    "    n_calib_queries = min(int(0.5 * np.sum(np.sum(mask_obs, axis=1) // k)), max_calib_queries)\n",
    "\n",
    "    print(f\"Estimating missingness with guessed rank {r}...\")\n",
    "    w_obs_est = estimate_P(mask_obs, 1, r=r, const=const)\n",
    "    print(\"Done estimating!\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    #------Sample test queries------#\n",
    "    #-------------------------------#\n",
    "    n_test_queries = min(int(0.99 * np.sum(np.sum(mask_test, axis=1) // k)), max_test_queries)\n",
    "    _, idxs_test, _ = sampler.sample_train_calib(mask_test, k, calib_size=n_test_queries, random_state=random_state)  \n",
    "    if verbose:\n",
    "        print(\"Training size:{}, calib size: {}, test size: {}\\n\".format(np.sum(mask_obs)-n_calib_queries*k, n_calib_queries, n_test_queries))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "\n",
    "    #------Split train calib--------#\n",
    "    #-------------------------------#\n",
    "    mask_train, idxs_calib, _ = sampler.sample_train_calib(mask_obs, k, \n",
    "                                calib_size=n_calib_queries, random_state=random_state)\n",
    "\n",
    "    #--------Model Training---------#\n",
    "    #-------------------------------#\n",
    "    print(\"Running matrix completion algorithm on the splitted training set...\")\n",
    "    sys.stdout.flush()\n",
    "    if solver == \"pmf\":\n",
    "        Mhat, _, _ = pmf_solve(M, mask_train, k=r_solver, verbose=verbose, random_state=random_state)\n",
    "    elif solver == \"svt\":\n",
    "        Mhat = svt_solve(M, mask_train, verbose = verbose, random_state = random_state)\n",
    "    print(\"Done training!\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    #------Compute intervals--------# \n",
    "    #-------------------------------#\n",
    "    # Evaluate the CI and quantile inflation weights using oracle obs sampling weights\n",
    "    ci_method = SimulCI(M, Mhat, mask_obs, idxs_calib, k, w_obs=w_obs)\n",
    "    df = ci_method.get_CI(idxs_test, alpha, allow_inf=allow_inf, store_weights=True)\n",
    "    lower, upper, is_inf= df.loc[0].lower, df.loc[0].upper, df.loc[0].is_inf\n",
    "    res = pd.concat([res, evaluate_SCI(lower, upper, k, M, idxs_test, is_inf=is_inf, metric='mean',method=\"conformal\")])\n",
    "    \n",
    "    # Evaluate the CI and quantile inflation weights using estimated obs sampling weights\n",
    "    ci_est = SimulCI(M, Mhat, mask_obs, idxs_calib, k, w_obs=w_obs_est)\n",
    "    df = ci_est.get_CI(idxs_test, alpha, allow_inf=allow_inf, store_weights=True)\n",
    "    lower, upper, is_inf= df.loc[0].lower, df.loc[0].upper, df.loc[0].is_inf\n",
    "    res = pd.concat([res, evaluate_SCI(lower, upper, k, M, idxs_test, is_inf=is_inf, metric='mean',method=\"est\")])\n",
    "\n",
    "    # Evaluate the estimation gap\n",
    "    weights_list = ci_method.weights_list\n",
    "    est_weights_list = ci_est.weights_list\n",
    "    est_gaps =[0.5*np.sum(np.abs(weights_list[i]-est_weights_list[i])) for i in range(len(weights_list))]\n",
    "    avg_gap = np.mean(est_gaps)\n",
    "\n",
    "\n",
    "    res['k'] = k \n",
    "    res['avg_gap'] = avg_gap   \n",
    "    res['Calib_queries'] = n_calib_queries\n",
    "    res['Train_entries'] = np.sum(mask_train)\n",
    "    res['Test_queries'] = n_test_queries\n",
    "    res['random_state'] = random_state\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7723ffe4-3beb-4c0f-85d0-95eb26408957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k:   0%|                                                                                         | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating missingness with guessed rank 8...\n",
      "iter: 1\n",
      "iter: 2\n",
      "iter: 3\n",
      "iter: 4\n",
      "iter: 5\n",
      "iter: 6\n",
      "iter: 7\n",
      "iter: 8\n",
      "iter: 9\n",
      "iter: 10\n",
      "iter: 11\n",
      "Function value changing by less than progTol\n",
      "Done estimating!\n",
      "\n",
      "Training size:17000, calib size: 2000, test size: 100\n",
      "\n",
      "Running matrix completion algorithm on the splitted training set...\n",
      "Iteration: 1; Rel error: 1.0000; Rank: 0\n",
      "Iteration: 11; Rel error: 0.2257; Rank: 8\n",
      "Iteration: 21; Rel error: 0.1677; Rank: 19\n",
      "Iteration: 31; Rel error: 0.3503; Rank: 36\n",
      "Iteration: 41; Rel error: 0.4328; Rank: 50\n",
      "Iteration: 51; Rel error: 0.4309; Rank: 60\n",
      "Iteration: 61; Rel error: 0.5889; Rank: 69\n",
      "Iteration: 71; Rel error: 0.4358; Rank: 46\n",
      "Iteration: 81; Rel error: 0.6064; Rank: 76\n",
      "Iteration: 91; Rel error: 0.4526; Rank: 47\n",
      "Iteration: 101; Rel error: 0.6127; Rank: 79\n",
      "Iteration: 111; Rel error: 0.4634; Rank: 48\n",
      "Iteration: 121; Rel error: 0.6147; Rank: 80\n",
      "Iteration: 131; Rel error: 0.4702; Rank: 49\n",
      "Iteration: 141; Rel error: 0.6153; Rank: 81\n",
      "Iteration: 151; Rel error: 0.4758; Rank: 49\n",
      "Iteration: 161; Rel error: 0.6156; Rank: 81\n",
      "Iteration: 171; Rel error: 0.4788; Rank: 49\n",
      "Iteration: 181; Rel error: 0.6160; Rank: 82\n",
      "Iteration: 191; Rel error: 0.4812; Rank: 49\n",
      "Done training!\n",
      "\n",
      "> \u001b[1;32mc:\\users\\liang\\appdata\\local\\temp\\ipykernel_11960\\3674128489.py\u001b[0m(55)\u001b[0;36mrun_single_experiment\u001b[1;34m()\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k:   0%|                                                                                         | 0/1 [06:41<?, ?it/s]\n",
      "Repetitions:   0%|                                                                               | 0/1 [06:41<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "#  Run Experiments  #\n",
    "#####################\n",
    "results = pd.DataFrame({})\n",
    "\n",
    "for i in tqdm(range(1, repetition+1), desc=\"Repetitions\", leave=True, position=0):\n",
    "    #random_state = repetition * (seed-1) + i\n",
    "    random_state=280\n",
    "    for k in tqdm(k_list, desc=\"k\", leave=True, position=0):\n",
    "\n",
    "        res = run_single_experiment(M, k, alpha, prop_obs, max_test_queries, max_calib_queries,\n",
    "                            r, scale=scale, random_state=random_state)\n",
    "        \n",
    "        results = pd.concat([results, res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6ebfa7fd-ecb6-440e-8dfb-c855018af652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query_coverage</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Size</th>\n",
       "      <th>metric</th>\n",
       "      <th>Inf_prop</th>\n",
       "      <th>Method</th>\n",
       "      <th>k</th>\n",
       "      <th>avg_gap</th>\n",
       "      <th>Calib_queries</th>\n",
       "      <th>Train_entries</th>\n",
       "      <th>Test_queries</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3.029717</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conformal</td>\n",
       "      <td>5</td>\n",
       "      <td>0.181221</td>\n",
       "      <td>2000</td>\n",
       "      <td>17000</td>\n",
       "      <td>100</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3.121167</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>est</td>\n",
       "      <td>5</td>\n",
       "      <td>0.181221</td>\n",
       "      <td>2000</td>\n",
       "      <td>17000</td>\n",
       "      <td>100</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Query_coverage  Coverage      Size metric  Inf_prop     Method  k  \\\n",
       "0            0.89      0.97  3.029717   mean       0.0  conformal  5   \n",
       "0            0.89      0.97  3.121167   mean       0.0        est  5   \n",
       "\n",
       "    avg_gap  Calib_queries  Train_entries  Test_queries  random_state  \n",
       "0  0.181221           2000          17000           100           280  \n",
       "0  0.181221           2000          17000           100           280  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7ddad-e9a0-4d88-a6ef-751ac9f3ec4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
