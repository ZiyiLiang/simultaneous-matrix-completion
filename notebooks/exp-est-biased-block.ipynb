{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "30320a16-e700-4f9e-a27e-efe00921f1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('../smc')\n",
    "sys.path.append('../third_party')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3b51d281-663f-4476-afc2-bf1f3edcdffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import *     # contains some useful helper functions \n",
    "from models import *    # toy models\n",
    "from solvers import *   # matrix completion solvers\n",
    "from methods import *\n",
    "from missingness_estimation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cb14887a-b24e-4a77-a18f-d756193d9418",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 5\n",
    "seed = 1\n",
    "\n",
    "# Fixed data parameters\n",
    "max_test_queries = 100            \n",
    "max_calib_queries = 2000\n",
    "matrix_generation_seed = 2024    # Data matrix is fixed \n",
    "\n",
    "n1 = n2 = 300\n",
    "\n",
    "model = \"RFM\"\n",
    "solver = \"pmf\"\n",
    "r_solver = 8\n",
    "prop_obs = 0.3\n",
    "\n",
    "# Other parameters\n",
    "verbose = True\n",
    "allow_inf = False\n",
    "alpha = 0.1\n",
    "\n",
    "scale=1\n",
    "const=1\n",
    "\n",
    "\n",
    "k_list = [5]\n",
    "repetition = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9cb59e52-48c1-4186-a16c-4b1c6b861cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing the ground truth matrix generated from the RFM model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# Generate Data #\n",
    "#################\n",
    "if model == \"RFM\":\n",
    "    mm = RandomFactorizationModel(n1 ,n2, 8)\n",
    "elif model == \"ROM\":\n",
    "    mm = RandomOrthogonalModel(n1 ,n2, 8)\n",
    "else:\n",
    "    mm = RandomFactorizationModel(n1 ,n2, 8)\n",
    "\n",
    "if verbose:\n",
    "    print('Fixing the ground truth matrix generated from the {} model.\\n'.format(model))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "U, V, M = mm.sample_noiseless(matrix_generation_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c01dab40-64fb-4b30-982d-b16a6d454405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Define Experiment #\n",
    "#####################\n",
    "def run_single_experiment(M_true, k, alpha, prop_obs, max_test_queries, max_calib_queries,\n",
    "                          r, scale, random_state=0):\n",
    "    res = pd.DataFrame({})\n",
    "\n",
    "\n",
    "    #--------Observation bias-------#\n",
    "    #-------------------------------#\n",
    "    n1, n2 = M_true.shape\n",
    "    bm = SamplingBias(n1,n2, normalize=False)\n",
    "    w_obs = bm.block_weights(ratio=alpha, scale=scale, random_state=random_state)\n",
    "\n",
    "    #-------Generate masks----------#\n",
    "    #-------------------------------#\n",
    "    sampler = QuerySampling(n1,n2)\n",
    "    mask_obs, mask_test = sampler.sample_submask(sub_size=prop_obs, w=w_obs, random_state=random_state)\n",
    "    n_calib_queries = min(int(0.5 * np.sum(np.sum(mask_obs, axis=1) // k)), max_calib_queries)\n",
    "\n",
    "    print(f\"Estimating missingness with guessed rank {r}...\")\n",
    "    w_obs_est = estimate_P(mask_obs, 1, r=r, const=const)\n",
    "    print(\"Done estimating!\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    #------Sample test queries------#\n",
    "    #-------------------------------#\n",
    "    n_test_queries = min(int(0.99 * np.sum(np.sum(mask_test, axis=1) // k)), max_test_queries)\n",
    "    _, idxs_test, _ = sampler.sample_train_calib(mask_test, k, calib_size=n_test_queries, random_state=random_state)  \n",
    "    if verbose:\n",
    "        print(\"Training size:{}, calib size: {}, test size: {}\\n\".format(np.sum(mask_obs)-n_calib_queries*k, n_calib_queries, n_test_queries))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "\n",
    "    #------Split train calib--------#\n",
    "    #-------------------------------#\n",
    "    mask_train, idxs_calib, _ = sampler.sample_train_calib(mask_obs, k, \n",
    "                                calib_size=n_calib_queries, random_state=random_state)\n",
    "\n",
    "    #--------Model Training---------#\n",
    "    #-------------------------------#\n",
    "    print(\"Running matrix completion algorithm on the splitted training set...\")\n",
    "    sys.stdout.flush()\n",
    "    if solver == \"pmf\":\n",
    "        Mhat, _, _ = pmf_solve(M, mask_train, k=r_solver, verbose=verbose, random_state=random_state)\n",
    "    elif solver == \"svt\":\n",
    "        Mhat = svt_solve(M, mask_train, verbose = verbose, random_state = random_state)\n",
    "    print(\"Done training!\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    pdb.set_trace()\n",
    "    #------Compute intervals--------# \n",
    "    #-------------------------------#\n",
    "    # Evaluate the CI and quantile inflation weights using oracle obs sampling weights\n",
    "    ci_method = SimulCI(M, Mhat, mask_obs, idxs_calib, k, w_obs=w_obs)\n",
    "    df = ci_method.get_CI(idxs_test, alpha, allow_inf=allow_inf, store_weights=True)\n",
    "    lower, upper, is_inf= df.loc[0].lower, df.loc[0].upper, df.loc[0].is_inf\n",
    "    res = pd.concat([res, evaluate_SCI(lower, upper, k, M, idxs_test, is_inf=is_inf, metric='mean',method=\"conformal\")])\n",
    "    \n",
    "    # Evaluate the CI and quantile inflation weights using estimated obs sampling weights\n",
    "    ci_est = SimulCI(M, Mhat, mask_obs, idxs_calib, k, w_obs=w_obs_est)\n",
    "    df = ci_est.get_CI(idxs_test, alpha, allow_inf=allow_inf, store_weights=True)\n",
    "    lower, upper, is_inf= df.loc[0].lower, df.loc[0].upper, df.loc[0].is_inf\n",
    "    res = pd.concat([res, evaluate_SCI(lower, upper, k, M, idxs_test, is_inf=is_inf, metric='mean',method=\"est\")])\n",
    "\n",
    "    # Evaluate the estimation gap\n",
    "    weights_list = ci_method.weights_list\n",
    "    est_weights_list = ci_est.weights_list\n",
    "    est_gaps =[0.5*np.sum(np.abs(weights_list[i]-est_weights_list[i])) for i in range(len(weights_list))]\n",
    "    avg_gap = np.mean(est_gaps)\n",
    "\n",
    "\n",
    "    res['k'] = k \n",
    "    res['avg_gap'] = avg_gap   \n",
    "    res['Calib_queries'] = n_calib_queries\n",
    "    res['Train_entries'] = np.sum(mask_train)\n",
    "    res['Test_queries'] = n_test_queries\n",
    "    res['random_state'] = random_state\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7723ffe4-3beb-4c0f-85d0-95eb26408957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k:   0%|                                                                                         | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating missingness with guessed rank 5...\n",
      "iter: 1\n",
      "iter: 2\n",
      "iter: 3\n",
      "iter: 4\n",
      "iter: 5\n",
      "iter: 6\n",
      "iter: 7\n",
      "Function value changing by less than progTol\n",
      "Done estimating!\n",
      "\n",
      "Training size:17000, calib size: 2000, test size: 100\n",
      "\n",
      "Running matrix completion algorithm on the splitted training set...\n",
      "Iteration: 1; Mean diff: 0.0113\n",
      "Iteration: 2; Mean diff: 0.0062\n",
      "Iteration: 3; Mean diff: 0.0051\n",
      "Iteration: 4; Mean diff: 0.0034\n",
      "Iteration: 5; Mean diff: 0.0024\n",
      "Iteration: 6; Mean diff: 0.0031\n",
      "Iteration: 7; Mean diff: 0.0028\n",
      "Iteration: 8; Mean diff: 0.0024\n",
      "Iteration: 9; Mean diff: 0.0021\n",
      "Iteration: 10; Mean diff: 0.0019\n",
      "Iteration: 11; Mean diff: 0.0016\n",
      "Iteration: 12; Mean diff: 0.0013\n",
      "Iteration: 13; Mean diff: 0.0011\n",
      "Iteration: 14; Mean diff: 0.0009\n",
      "Iteration: 15; Mean diff: 0.0007\n",
      "Iteration: 16; Mean diff: 0.0006\n",
      "Iteration: 17; Mean diff: 0.0005\n",
      "Iteration: 18; Mean diff: 0.0004\n",
      "Iteration: 19; Mean diff: 0.0004\n",
      "Iteration: 20; Mean diff: 0.0003\n",
      "Iteration: 21; Mean diff: 0.0003\n",
      "Iteration: 22; Mean diff: 0.0003\n",
      "Iteration: 23; Mean diff: 0.0003\n",
      "Iteration: 24; Mean diff: 0.0003\n",
      "Iteration: 25; Mean diff: 0.0003\n",
      "Iteration: 26; Mean diff: 0.0002\n",
      "Iteration: 27; Mean diff: 0.0002\n",
      "Iteration: 28; Mean diff: 0.0002\n",
      "Iteration: 29; Mean diff: 0.0002\n",
      "Iteration: 30; Mean diff: 0.0002\n",
      "Iteration: 31; Mean diff: 0.0002\n",
      "Iteration: 32; Mean diff: 0.0002\n",
      "Iteration: 33; Mean diff: 0.0002\n",
      "Iteration: 34; Mean diff: 0.0002\n",
      "Iteration: 35; Mean diff: 0.0002\n",
      "Iteration: 36; Mean diff: 0.0001\n",
      "Iteration: 37; Mean diff: 0.0001\n",
      "Iteration: 38; Mean diff: 0.0001\n",
      "Iteration: 39; Mean diff: 0.0001\n",
      "Iteration: 40; Mean diff: 0.0001\n",
      "Iteration: 41; Mean diff: 0.0001\n",
      "Iteration: 42; Mean diff: 0.0001\n",
      "Iteration: 43; Mean diff: 0.0001\n",
      "Iteration: 44; Mean diff: 0.0001\n",
      "Iteration: 45; Mean diff: 0.0001\n",
      "Iteration: 46; Mean diff: 0.0001\n",
      "Iteration: 47; Mean diff: 0.0001\n",
      "Iteration: 48; Mean diff: 0.0001\n",
      "Iteration: 49; Mean diff: 0.0001\n",
      "Iteration: 50; Mean diff: 0.0001\n",
      "Iteration: 51; Mean diff: 0.0001\n",
      "Iteration: 52; Mean diff: 0.0001\n",
      "Iteration: 53; Mean diff: 0.0001\n",
      "Iteration: 54; Mean diff: 0.0001\n",
      "Iteration: 55; Mean diff: 0.0001\n",
      "Iteration: 56; Mean diff: 0.0001\n",
      "Iteration: 57; Mean diff: 0.0001\n",
      "Iteration: 58; Mean diff: 0.0001\n",
      "Iteration: 59; Mean diff: 0.0001\n",
      "Iteration: 60; Mean diff: 0.0001\n",
      "Iteration: 61; Mean diff: 0.0001\n",
      "Iteration: 62; Mean diff: 0.0001\n",
      "Iteration: 63; Mean diff: 0.0001\n",
      "Iteration: 64; Mean diff: 0.0001\n",
      "Iteration: 65; Mean diff: 0.0001\n",
      "Iteration: 66; Mean diff: 0.0001\n",
      "Iteration: 67; Mean diff: 0.0001\n",
      "Iteration: 68; Mean diff: 0.0001\n",
      "Iteration: 69; Mean diff: 0.0001\n",
      "Iteration: 70; Mean diff: 0.0001\n",
      "Iteration: 71; Mean diff: 0.0001\n",
      "Iteration: 72; Mean diff: 0.0001\n",
      "Iteration: 73; Mean diff: 0.0001\n",
      "Iteration: 74; Mean diff: 0.0001\n",
      "Iteration: 75; Mean diff: 0.0001\n",
      "Iteration: 76; Mean diff: 0.0001\n",
      "Iteration: 77; Mean diff: 0.0001\n",
      "Iteration: 78; Mean diff: 0.0001\n",
      "Iteration: 79; Mean diff: 0.0001\n",
      "Iteration: 80; Mean diff: 0.0001\n",
      "Iteration: 81; Mean diff: 0.0001\n",
      "Iteration: 82; Mean diff: 0.0001\n",
      "Iteration: 83; Mean diff: 0.0001\n",
      "Iteration: 84; Mean diff: 0.0001\n",
      "Iteration: 85; Mean diff: 0.0001\n",
      "Iteration: 86; Mean diff: 0.0001\n",
      "Iteration: 87; Mean diff: 0.0001\n",
      "Iteration: 88; Mean diff: 0.0001\n",
      "Iteration: 89; Mean diff: 0.0001\n",
      "Iteration: 90; Mean diff: 0.0001\n",
      "Iteration: 91; Mean diff: 0.0001\n",
      "Iteration: 92; Mean diff: 0.0001\n",
      "Iteration: 93; Mean diff: 0.0001\n",
      "Iteration: 94; Mean diff: 0.0001\n",
      "Iteration: 95; Mean diff: 0.0001\n",
      "Iteration: 96; Mean diff: 0.0001\n",
      "Iteration: 97; Mean diff: 0.0001\n",
      "Iteration: 98; Mean diff: 0.0001\n",
      "Iteration: 99; Mean diff: 0.0001\n",
      "Iteration: 100; Mean diff: 0.0001\n",
      "Iteration: 101; Mean diff: 0.0001\n",
      "Iteration: 102; Mean diff: 0.0001\n",
      "Iteration: 103; Mean diff: 0.0001\n",
      "Iteration: 104; Mean diff: 0.0001\n",
      "Iteration: 105; Mean diff: 0.0001\n",
      "Iteration: 106; Mean diff: 0.0001\n",
      "Iteration: 107; Mean diff: 0.0001\n",
      "Iteration: 108; Mean diff: 0.0001\n",
      "Iteration: 109; Mean diff: 0.0001\n",
      "Iteration: 110; Mean diff: 0.0001\n",
      "Iteration: 111; Mean diff: 0.0001\n",
      "Iteration: 112; Mean diff: 0.0001\n",
      "Iteration: 113; Mean diff: 0.0001\n",
      "Iteration: 114; Mean diff: 0.0001\n",
      "Iteration: 115; Mean diff: 0.0001\n",
      "Iteration: 116; Mean diff: 0.0001\n",
      "Iteration: 117; Mean diff: 0.0001\n",
      "Iteration: 118; Mean diff: 0.0001\n",
      "Iteration: 119; Mean diff: 0.0001\n",
      "Iteration: 120; Mean diff: 0.0001\n",
      "Iteration: 121; Mean diff: 0.0001\n",
      "Iteration: 122; Mean diff: 0.0001\n",
      "Iteration: 123; Mean diff: 0.0001\n",
      "Iteration: 124; Mean diff: 0.0001\n",
      "Iteration: 125; Mean diff: 0.0001\n",
      "Iteration: 126; Mean diff: 0.0001\n",
      "Iteration: 127; Mean diff: 0.0001\n",
      "Iteration: 128; Mean diff: 0.0001\n",
      "Iteration: 129; Mean diff: 0.0001\n",
      "Iteration: 130; Mean diff: 0.0001\n",
      "Iteration: 131; Mean diff: 0.0001\n",
      "Iteration: 132; Mean diff: 0.0001\n",
      "Iteration: 133; Mean diff: 0.0001\n",
      "Iteration: 134; Mean diff: 0.0001\n",
      "Iteration: 135; Mean diff: 0.0001\n",
      "Iteration: 136; Mean diff: 0.0001\n",
      "Iteration: 137; Mean diff: 0.0001\n",
      "Iteration: 138; Mean diff: 0.0001\n",
      "Iteration: 139; Mean diff: 0.0001\n",
      "Iteration: 140; Mean diff: 0.0001\n",
      "Iteration: 141; Mean diff: 0.0001\n",
      "Iteration: 142; Mean diff: 0.0001\n",
      "Iteration: 143; Mean diff: 0.0001\n",
      "Iteration: 144; Mean diff: 0.0001\n",
      "Iteration: 145; Mean diff: 0.0001\n",
      "Iteration: 146; Mean diff: 0.0001\n",
      "Iteration: 147; Mean diff: 0.0001\n",
      "Iteration: 148; Mean diff: 0.0001\n",
      "Iteration: 149; Mean diff: 0.0001\n",
      "Iteration: 150; Mean diff: 0.0001\n",
      "Iteration: 151; Mean diff: 0.0001\n",
      "Iteration: 152; Mean diff: 0.0001\n",
      "Iteration: 153; Mean diff: 0.0001\n",
      "Iteration: 154; Mean diff: 0.0001\n",
      "Iteration: 155; Mean diff: 0.0001\n",
      "Iteration: 156; Mean diff: 0.0001\n",
      "Iteration: 157; Mean diff: 0.0001\n",
      "Iteration: 158; Mean diff: 0.0001\n",
      "Iteration: 159; Mean diff: 0.0001\n",
      "Iteration: 160; Mean diff: 0.0001\n",
      "Iteration: 161; Mean diff: 0.0001\n",
      "Iteration: 162; Mean diff: 0.0001\n",
      "Iteration: 163; Mean diff: 0.0001\n",
      "Iteration: 164; Mean diff: 0.0001\n",
      "Iteration: 165; Mean diff: 0.0001\n",
      "Iteration: 166; Mean diff: 0.0001\n",
      "Iteration: 167; Mean diff: 0.0001\n",
      "Iteration: 168; Mean diff: 0.0001\n",
      "Iteration: 169; Mean diff: 0.0001\n",
      "Iteration: 170; Mean diff: 0.0001\n",
      "Iteration: 171; Mean diff: 0.0001\n",
      "Iteration: 172; Mean diff: 0.0001\n",
      "Iteration: 173; Mean diff: 0.0001\n",
      "Iteration: 174; Mean diff: 0.0001\n",
      "Iteration: 175; Mean diff: 0.0001\n",
      "Iteration: 176; Mean diff: 0.0001\n",
      "Iteration: 177; Mean diff: 0.0001\n",
      "Iteration: 178; Mean diff: 0.0001\n",
      "Iteration: 179; Mean diff: 0.0001\n",
      "Iteration: 180; Mean diff: 0.0001\n",
      "Iteration: 181; Mean diff: 0.0001\n",
      "Iteration: 182; Mean diff: 0.0001\n",
      "Iteration: 183; Mean diff: 0.0001\n",
      "Iteration: 184; Mean diff: 0.0001\n",
      "Iteration: 185; Mean diff: 0.0001\n",
      "Iteration: 186; Mean diff: 0.0001\n",
      "Iteration: 187; Mean diff: 0.0001\n",
      "Iteration: 188; Mean diff: 0.0001\n",
      "Iteration: 189; Mean diff: 0.0001\n",
      "Iteration: 190; Mean diff: 0.0001\n",
      "Iteration: 191; Mean diff: 0.0001\n",
      "Iteration: 192; Mean diff: 0.0001\n",
      "Iteration: 193; Mean diff: 0.0001\n",
      "Iteration: 194; Mean diff: 0.0001\n",
      "Iteration: 195; Mean diff: 0.0001\n",
      "Iteration: 196; Mean diff: 0.0001\n",
      "Iteration: 197; Mean diff: 0.0001\n",
      "Iteration: 198; Mean diff: 0.0001\n",
      "Iteration: 199; Mean diff: 0.0001\n",
      "Iteration: 200; Mean diff: 0.0001\n",
      "Done training!\n",
      "\n",
      "> \u001b[1;32mc:\\users\\liang\\appdata\\local\\temp\\ipykernel_21440\\3674128489.py\u001b[0m(55)\u001b[0;36mrun_single_experiment\u001b[1;34m()\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  abs_error=np.abs(M-Mhat)\n",
      "ipdb>  np.max(abs_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238.47268540603955\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  st_error=np.sort(abs_error)\n",
      "ipdb>  st_error[:10,]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[1.26813044e-03, 1.36624284e-03, 1.68469236e-03, ...,\n",
      "        2.21529160e+00, 2.37000794e+00, 2.51928581e+00],\n",
      "       [5.54841740e-04, 1.00550383e-03, 1.07928281e-03, ...,\n",
      "        1.06699126e+00, 1.22011176e+00, 1.45633018e+00],\n",
      "       [2.06885232e-04, 3.15517805e-04, 1.07185129e-03, ...,\n",
      "        1.48260457e+00, 1.65836699e+00, 3.38272340e+00],\n",
      "       ...,\n",
      "       [5.04918735e-04, 8.82434549e-04, 1.58238584e-03, ...,\n",
      "        1.68213564e+00, 1.69074844e+00, 1.85404840e+00],\n",
      "       [7.81883239e-04, 1.42384540e-03, 1.99727049e-03, ...,\n",
      "        1.44736910e+00, 1.45934858e+00, 1.85255117e+00],\n",
      "       [7.75578029e-04, 2.02094819e-03, 2.12070836e-03, ...,\n",
      "        2.22248551e+00, 2.46207658e+00, 5.22765114e+00]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  st_error=np.sort(abs_error.flatten())\n",
      "ipdb>  st_error[:10,]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([1.12238868e-06, 1.17171943e-06, 9.81122902e-06, 1.18422790e-05,\n",
      "       1.48880692e-05, 1.53923977e-05, 2.13961910e-05, 2.19903669e-05,\n",
      "       2.21952427e-05, 2.33173269e-05])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  len(st_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  st_error[-10:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([147.08772997, 150.2350818 , 150.6002389 , 154.81500348,\n",
      "       155.9911752 , 160.39066022, 171.3777004 , 193.76767636,\n",
      "       208.68365121, 238.47268541])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  st_error[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([ 59.48848362,  59.72337166,  59.98976688,  60.57024964,\n",
      "        61.25988508,  61.55882608,  61.69753601,  61.87170067,\n",
      "        62.22750018,  62.79400974,  62.82376822,  63.7140636 ,\n",
      "        63.73282804,  63.78550341,  63.93912182,  64.5519541 ,\n",
      "        65.0250892 ,  65.12807261,  65.28165291,  66.21761226,\n",
      "        66.72704538,  67.77652024,  68.09658306,  69.62749021,\n",
      "        69.94256752,  70.27147151,  71.08602026,  71.24570514,\n",
      "        71.27522382,  71.4222057 ,  73.80518944,  74.85056493,\n",
      "        78.42006011,  81.98924925,  82.29645352,  83.50305094,\n",
      "        83.76998402,  83.85573092,  84.32565618,  84.33604986,\n",
      "        86.47093676,  86.47309443,  87.05265543,  87.64955438,\n",
      "        88.13713681,  88.94132684,  90.51134255,  91.63737762,\n",
      "        93.20284282,  94.70001843,  94.857128  ,  98.10512915,\n",
      "        98.37387759,  99.13336871,  99.93269148, 100.4653572 ,\n",
      "       102.53860382, 102.93216462, 103.92960742, 105.18867721,\n",
      "       105.35162022, 106.59743727, 107.09373663, 107.56097602,\n",
      "       108.01895936, 110.01819848, 111.38270832, 113.43369463,\n",
      "       114.11859105, 115.57275745, 115.76503252, 116.66970687,\n",
      "       118.81774052, 119.86713522, 120.34901144, 121.25047624,\n",
      "       121.87515808, 123.49203912, 126.01628685, 126.27259025,\n",
      "       128.50413907, 129.26569583, 130.63276104, 132.06646549,\n",
      "       135.35542443, 136.58191763, 139.62353756, 140.63747512,\n",
      "       143.95875474, 144.45840081, 147.08772997, 150.2350818 ,\n",
      "       150.6002389 , 154.81500348, 155.9911752 , 160.39066022,\n",
      "       171.3777004 , 193.76767636, 208.68365121, 238.47268541])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  plt.hist(st_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([8.9823e+04, 6.0000e+01, 4.7000e+01, 2.1000e+01, 2.2000e+01,\n",
      "       1.5000e+01, 8.0000e+00, 1.0000e+00, 2.0000e+00, 1.0000e+00]), array([1.12238868e-06, 2.38472696e+01, 4.76945380e+01, 7.15418064e+01,\n",
      "       9.53890748e+01, 1.19236343e+02, 1.43083612e+02, 1.66930880e+02,\n",
      "       1.90778149e+02, 2.14625417e+02, 2.38472685e+02]), <BarContainer object of 10 artists>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  plt.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  np.sum(st_error>20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  np.sum(st_error>1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3696\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k:   0%|                                                                                         | 0/1 [21:56<?, ?it/s]\n",
      "Repetitions:   0%|                                                                               | 0/1 [21:56<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "#  Run Experiments  #\n",
    "#####################\n",
    "results = pd.DataFrame({})\n",
    "\n",
    "for i in tqdm(range(1, repetition+1), desc=\"Repetitions\", leave=True, position=0):\n",
    "    #random_state = repetition * (seed-1) + i\n",
    "    random_state=280\n",
    "    for k in tqdm(k_list, desc=\"k\", leave=True, position=0):\n",
    "\n",
    "        res = run_single_experiment(M, k, alpha, prop_obs, max_test_queries, max_calib_queries,\n",
    "                            r, scale=scale, random_state=random_state)\n",
    "        \n",
    "        results = pd.concat([results, res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6ebfa7fd-ecb6-440e-8dfb-c855018af652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query_coverage</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Size</th>\n",
       "      <th>metric</th>\n",
       "      <th>Inf_prop</th>\n",
       "      <th>Method</th>\n",
       "      <th>k</th>\n",
       "      <th>avg_gap</th>\n",
       "      <th>Calib_queries</th>\n",
       "      <th>Train_entries</th>\n",
       "      <th>Test_queries</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3.029717</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conformal</td>\n",
       "      <td>5</td>\n",
       "      <td>0.181221</td>\n",
       "      <td>2000</td>\n",
       "      <td>17000</td>\n",
       "      <td>100</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3.121167</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>est</td>\n",
       "      <td>5</td>\n",
       "      <td>0.181221</td>\n",
       "      <td>2000</td>\n",
       "      <td>17000</td>\n",
       "      <td>100</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Query_coverage  Coverage      Size metric  Inf_prop     Method  k  \\\n",
       "0            0.89      0.97  3.029717   mean       0.0  conformal  5   \n",
       "0            0.89      0.97  3.121167   mean       0.0        est  5   \n",
       "\n",
       "    avg_gap  Calib_queries  Train_entries  Test_queries  random_state  \n",
       "0  0.181221           2000          17000           100           280  \n",
       "0  0.181221           2000          17000           100           280  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7ddad-e9a0-4d88-a6ef-751ac9f3ec4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
