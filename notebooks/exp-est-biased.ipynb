{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30320a16-e700-4f9e-a27e-efe00921f1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('../smc')\n",
    "sys.path.append('../third_party')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b51d281-663f-4476-afc2-bf1f3edcdffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import *     # contains some useful helper functions \n",
    "from models import *    # toy models\n",
    "from solvers import *   # matrix completion solvers\n",
    "from methods import *\n",
    "from missingness_estimation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb14887a-b24e-4a77-a18f-d756193d9418",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 5\n",
    "scale = 1\n",
    "seed = 1\n",
    "\n",
    "# Fixed data parameters\n",
    "max_test_queries = 100            \n",
    "max_calib_queries = 2000\n",
    "matrix_generation_seed = 2024    # Data matrix is fixed \n",
    "\n",
    "n1 = n2 = 400\n",
    "\n",
    "model = \"RFM\"\n",
    "solver = \"pmf\"\n",
    "prop_obs = 0.3\n",
    "\n",
    "\n",
    "# Other parameters\n",
    "verbose = True\n",
    "allow_inf = False\n",
    "alpha = 0.1\n",
    "\n",
    "k_list = [2,5,8]\n",
    "repetition = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cb59e52-48c1-4186-a16c-4b1c6b861cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing the ground truth matrix generated from the RFM model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# Generate Data #\n",
    "#################\n",
    "if model == \"RFM\":\n",
    "    mm = RandomFactorizationModel(n1 ,n2, 8)\n",
    "elif model == \"ROM\":\n",
    "    mm = RandomOrthogonalModel(n1 ,n2, 8)\n",
    "else:\n",
    "    mm = RandomFactorizationModel(n1 ,n2, 8)\n",
    "\n",
    "if verbose:\n",
    "    print('Fixing the ground truth matrix generated from the {} model.\\n'.format(model))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "U, V, M = mm.sample_noiseless(matrix_generation_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c01dab40-64fb-4b30-982d-b16a6d454405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Define Experiment #\n",
    "#####################\n",
    "def run_single_experiment(M_true, k, alpha, prop_obs, max_test_queries, max_calib_queries,\n",
    "                          r,scale, random_state=0):\n",
    "    res = pd.DataFrame({})\n",
    "\n",
    "\n",
    "    #--------Observation bias-------#\n",
    "    #-------------------------------#\n",
    "    n1, n2 = M_true.shape\n",
    "    bm = SamplingBias(n1,n2)\n",
    "    w_obs = bm.inc_weights(scale = scale)\n",
    "\n",
    "    #-------Generate masks----------#\n",
    "    #-------------------------------#\n",
    "    sampler = QuerySampling(n1,n2)\n",
    "    mask_obs, mask_test = sampler.sample_submask(sub_size=prop_obs, w=w_obs, random_state=random_state)\n",
    "    n_calib_queries = min(int(0.5 * np.sum(np.sum(mask_obs, axis=1) // k)), max_calib_queries)\n",
    "\n",
    "    print(f\"Estimating missingness with guessed rank {r}...\")\n",
    "    w_obs_est = estimate_P(mask_obs, 1, r=r)\n",
    "    print(\"Done estimating!\\n\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    #------Sample test queries------#\n",
    "    #-------------------------------#\n",
    "    n_test_queries = min(int(0.99 * np.sum(np.sum(mask_test, axis=1) // k)), max_test_queries)\n",
    "    _, idxs_test, _ = sampler.sample_train_calib(mask_test, k, calib_size=n_test_queries, random_state=random_state)  \n",
    "    if verbose:\n",
    "        print(\"Training size:{}, calib size: {}, test size: {}\\n\".format(np.sum(mask_obs)-n_calib_queries*k, n_calib_queries, n_test_queries))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "\n",
    "    #------Split train calib--------#\n",
    "    #-------------------------------#\n",
    "    mask_train, idxs_calib, _ = sampler.sample_train_calib(mask_obs, k, \n",
    "                                calib_size=n_calib_queries, random_state=random_state)\n",
    "\n",
    "    #--------Model Training---------#\n",
    "    #-------------------------------#\n",
    "    print(\"Running matrix completion algorithm on the splitted training set...\")\n",
    "    sys.stdout.flush()\n",
    "    if solver == \"pmf\":\n",
    "        Mhat, _, _ = pmf_solve(M, mask_train, k=r, verbose=verbose, random_state=random_state)\n",
    "    elif solver == \"svt\":\n",
    "        Mhat = svt_solve(M, mask_train, verbose = verbose, random_state = random_state)\n",
    "    print(\"Done training!\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "    #------Compute intervals--------# \n",
    "    #-------------------------------#\n",
    "\n",
    "    # Evaluate the CI and quantile inflation weights using oracle obs sampling weights\n",
    "    ci_method = SimulCI(M, Mhat, mask_obs, idxs_calib, k, w_obs=w_obs)\n",
    "    df = ci_method.get_CI(idxs_test, alpha, allow_inf=allow_inf, store_weights=True)\n",
    "    lower, upper, is_inf= df.loc[0].lower, df.loc[0].upper, df.loc[0].is_inf\n",
    "    res = pd.concat([res, evaluate_SCI(lower, upper, k, M, idxs_test, is_inf=is_inf, method=\"conformal\")])\n",
    "\n",
    "    # Evaluate the CI and quantile inflation weights using estimated obs sampling weights\n",
    "    ci_est = SimulCI(M, Mhat, mask_obs, idxs_calib, k, w_obs=w_obs_est)\n",
    "    df = ci_est.get_CI(idxs_test, alpha, allow_inf=allow_inf, store_weights=True)\n",
    "    lower, upper, is_inf= df.loc[0].lower, df.loc[0].upper, df.loc[0].is_inf\n",
    "    res = pd.concat([res, evaluate_SCI(lower, upper, k, M, idxs_test, is_inf=is_inf, method=\"est\")])\n",
    "\n",
    "    # Evaluate the estimation gap\n",
    "    weights_list = ci_method.weights_list\n",
    "    est_weights_list = ci_est.weights_list\n",
    "    est_gaps =[0.5*np.mean(np.abs(weights_list[i]-est_weights_list[i])) for i in range(len(weights_list))]\n",
    "    avg_gap = np.mean(est_gaps)\n",
    "\n",
    "\n",
    "    res['k'] = k \n",
    "    res['avg_gap'] = avg_gap   \n",
    "    res['Calib_queries'] = n_calib_queries\n",
    "    res['Train_entries'] = np.sum(mask_train)\n",
    "    res['Test_queries'] = n_test_queries\n",
    "    res['random_state'] = random_state\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7723ffe4-3beb-4c0f-85d0-95eb26408957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k:   0%|                                                                                         | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating missingness with guessed rank 5...\n",
      "iter: 1\n",
      "iter: 2\n",
      "iter: 3\n",
      "iter: 4\n",
      "iter: 5\n",
      "iter: 6\n",
      "iter: 7\n",
      "iter: 8\n",
      "iter: 9\n",
      "iter: 10\n",
      "iter: 11\n",
      "iter: 12\n",
      "iter: 13\n",
      "iter: 14\n",
      "Function value changing by less than progTol\n",
      "Done estimating!\n",
      "\n",
      "Training size:44000, calib size: 2000, test size: 100\n",
      "\n",
      "Running matrix completion algorithm on the splitted training set...\n",
      "Iteration: 1; Mean diff: 0.0080\n",
      "Iteration: 2; Mean diff: 0.0058\n",
      "Iteration: 3; Mean diff: 0.0035\n",
      "Iteration: 4; Mean diff: 0.0010\n",
      "Iteration: 5; Mean diff: 0.0006\n",
      "Iteration: 6; Mean diff: 0.0005\n",
      "Iteration: 7; Mean diff: 0.0004\n",
      "Iteration: 8; Mean diff: 0.0004\n",
      "Iteration: 9; Mean diff: 0.0003\n",
      "Iteration: 10; Mean diff: 0.0003\n",
      "Iteration: 11; Mean diff: 0.0003\n",
      "Iteration: 12; Mean diff: 0.0003\n",
      "Iteration: 13; Mean diff: 0.0002\n",
      "Iteration: 14; Mean diff: 0.0002\n",
      "Iteration: 15; Mean diff: 0.0002\n",
      "Iteration: 16; Mean diff: 0.0002\n",
      "Iteration: 17; Mean diff: 0.0003\n",
      "Iteration: 18; Mean diff: 0.0003\n",
      "Iteration: 19; Mean diff: 0.0003\n",
      "Iteration: 20; Mean diff: 0.0003\n",
      "Iteration: 21; Mean diff: 0.0003\n",
      "Iteration: 22; Mean diff: 0.0002\n",
      "Iteration: 23; Mean diff: 0.0002\n",
      "Iteration: 24; Mean diff: 0.0002\n",
      "Iteration: 25; Mean diff: 0.0002\n",
      "Iteration: 26; Mean diff: 0.0002\n",
      "Iteration: 27; Mean diff: 0.0001\n",
      "Iteration: 28; Mean diff: 0.0001\n",
      "Iteration: 29; Mean diff: 0.0001\n",
      "Iteration: 30; Mean diff: 0.0001\n",
      "Iteration: 31; Mean diff: 0.0001\n",
      "Iteration: 32; Mean diff: 0.0001\n",
      "Iteration: 33; Mean diff: 0.0001\n",
      "Iteration: 34; Mean diff: 0.0001\n",
      "Iteration: 35; Mean diff: 0.0001\n",
      "Iteration: 36; Mean diff: 0.0001\n",
      "Iteration: 37; Mean diff: 0.0001\n",
      "Iteration: 38; Mean diff: 0.0001\n",
      "Iteration: 39; Mean diff: 0.0000\n",
      "Iteration: 40; Mean diff: 0.0000\n",
      "Iteration: 41; Mean diff: 0.0000\n",
      "Iteration: 42; Mean diff: 0.0000\n",
      "Iteration: 43; Mean diff: 0.0000\n",
      "Iteration: 44; Mean diff: 0.0000\n",
      "Iteration: 45; Mean diff: 0.0000\n",
      "Iteration: 46; Mean diff: 0.0000\n",
      "Iteration: 47; Mean diff: 0.0000\n",
      "Iteration: 48; Mean diff: 0.0000\n",
      "Iteration: 49; Mean diff: 0.0000\n",
      "Iteration: 50; Mean diff: 0.0000\n",
      "Iteration: 51; Mean diff: 0.0000\n",
      "Iteration: 52; Mean diff: 0.0000\n",
      "Iteration: 53; Mean diff: 0.0000\n",
      "Iteration: 54; Mean diff: 0.0000\n",
      "Iteration: 55; Mean diff: 0.0000\n",
      "Iteration: 56; Mean diff: 0.0000\n",
      "Iteration: 57; Mean diff: 0.0000\n",
      "Iteration: 58; Mean diff: 0.0000\n",
      "Iteration: 59; Mean diff: 0.0000\n",
      "Iteration: 60; Mean diff: 0.0000\n",
      "Iteration: 61; Mean diff: 0.0000\n",
      "Iteration: 62; Mean diff: 0.0000\n",
      "Iteration: 63; Mean diff: 0.0000\n",
      "Iteration: 64; Mean diff: 0.0000\n",
      "Iteration: 65; Mean diff: 0.0000\n",
      "Iteration: 66; Mean diff: 0.0000\n",
      "Iteration: 67; Mean diff: 0.0000\n",
      "Iteration: 68; Mean diff: 0.0000\n",
      "Iteration: 69; Mean diff: 0.0000\n",
      "Iteration: 70; Mean diff: 0.0000\n",
      "Iteration: 71; Mean diff: 0.0000\n",
      "Iteration: 72; Mean diff: 0.0000\n",
      "Iteration: 73; Mean diff: 0.0000\n",
      "Iteration: 74; Mean diff: 0.0000\n",
      "Iteration: 75; Mean diff: 0.0000\n",
      "Iteration: 76; Mean diff: 0.0000\n",
      "Iteration: 77; Mean diff: 0.0000\n",
      "Iteration: 78; Mean diff: 0.0000\n",
      "Iteration: 79; Mean diff: 0.0000\n",
      "Iteration: 80; Mean diff: 0.0000\n",
      "Iteration: 81; Mean diff: 0.0000\n",
      "Iteration: 82; Mean diff: 0.0000\n",
      "Iteration: 83; Mean diff: 0.0000\n",
      "Iteration: 84; Mean diff: 0.0000\n",
      "Iteration: 85; Mean diff: 0.0000\n",
      "Iteration: 86; Mean diff: 0.0000\n",
      "Iteration: 87; Mean diff: 0.0000\n",
      "Iteration: 88; Mean diff: 0.0000\n",
      "Iteration: 89; Mean diff: 0.0000\n",
      "Iteration: 90; Mean diff: 0.0000\n",
      "Iteration: 91; Mean diff: 0.0000\n",
      "Iteration: 92; Mean diff: 0.0000\n",
      "Iteration: 93; Mean diff: 0.0000\n",
      "Iteration: 94; Mean diff: 0.0000\n",
      "Iteration: 95; Mean diff: 0.0000\n",
      "Iteration: 96; Mean diff: 0.0000\n",
      "Stopping criteria met, training terminated.\n",
      "Done training!\n",
      "\n",
      "Computing conformal prediction intervals for 100 test queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CI: 100%|████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 14.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Computing conformal prediction intervals for 100 test queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CI: 100%|████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "k:  33%|██████████████████████████▋                                                     | 1/3 [03:11<06:22, 191.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating missingness with guessed rank 5...\n",
      "iter: 1\n",
      "iter: 2\n",
      "iter: 3\n",
      "iter: 4\n",
      "iter: 5\n",
      "iter: 6\n",
      "iter: 7\n",
      "iter: 8\n",
      "iter: 9\n",
      "iter: 10\n",
      "iter: 11\n",
      "iter: 12\n",
      "iter: 13\n",
      "iter: 14\n",
      "Function value changing by less than progTol\n",
      "Done estimating!\n",
      "\n",
      "Training size:38000, calib size: 2000, test size: 100\n",
      "\n",
      "Running matrix completion algorithm on the splitted training set...\n",
      "Iteration: 1; Mean diff: 0.0075\n",
      "Iteration: 2; Mean diff: 0.0056\n",
      "Iteration: 3; Mean diff: 0.0033\n",
      "Iteration: 4; Mean diff: 0.0011\n",
      "Iteration: 5; Mean diff: 0.0006\n",
      "Iteration: 6; Mean diff: 0.0005\n",
      "Iteration: 7; Mean diff: 0.0004\n",
      "Iteration: 8; Mean diff: 0.0004\n",
      "Iteration: 9; Mean diff: 0.0003\n",
      "Iteration: 10; Mean diff: 0.0002\n",
      "Iteration: 11; Mean diff: 0.0002\n",
      "Iteration: 12; Mean diff: 0.0002\n",
      "Iteration: 13; Mean diff: 0.0001\n",
      "Iteration: 14; Mean diff: 0.0001\n",
      "Iteration: 15; Mean diff: 0.0001\n",
      "Iteration: 16; Mean diff: 0.0001\n",
      "Iteration: 17; Mean diff: 0.0001\n",
      "Iteration: 18; Mean diff: 0.0001\n",
      "Iteration: 19; Mean diff: 0.0001\n",
      "Iteration: 20; Mean diff: 0.0001\n",
      "Iteration: 21; Mean diff: 0.0001\n",
      "Iteration: 22; Mean diff: 0.0001\n",
      "Iteration: 23; Mean diff: 0.0001\n",
      "Iteration: 24; Mean diff: 0.0001\n",
      "Iteration: 25; Mean diff: 0.0001\n",
      "Iteration: 26; Mean diff: 0.0001\n",
      "Iteration: 27; Mean diff: 0.0001\n",
      "Iteration: 28; Mean diff: 0.0001\n",
      "Iteration: 29; Mean diff: 0.0001\n",
      "Iteration: 30; Mean diff: 0.0001\n",
      "Iteration: 31; Mean diff: 0.0001\n",
      "Iteration: 32; Mean diff: 0.0001\n",
      "Iteration: 33; Mean diff: 0.0001\n",
      "Iteration: 34; Mean diff: 0.0001\n",
      "Iteration: 35; Mean diff: 0.0001\n",
      "Iteration: 36; Mean diff: 0.0001\n",
      "Iteration: 37; Mean diff: 0.0001\n",
      "Iteration: 38; Mean diff: 0.0002\n",
      "Iteration: 39; Mean diff: 0.0002\n",
      "Iteration: 40; Mean diff: 0.0002\n",
      "Iteration: 41; Mean diff: 0.0002\n",
      "Iteration: 42; Mean diff: 0.0002\n",
      "Iteration: 43; Mean diff: 0.0002\n",
      "Iteration: 44; Mean diff: 0.0002\n",
      "Iteration: 45; Mean diff: 0.0002\n",
      "Iteration: 46; Mean diff: 0.0002\n",
      "Iteration: 47; Mean diff: 0.0002\n",
      "Iteration: 48; Mean diff: 0.0002\n",
      "Iteration: 49; Mean diff: 0.0001\n",
      "Iteration: 50; Mean diff: 0.0001\n",
      "Iteration: 51; Mean diff: 0.0001\n",
      "Iteration: 52; Mean diff: 0.0001\n",
      "Iteration: 53; Mean diff: 0.0001\n",
      "Iteration: 54; Mean diff: 0.0001\n",
      "Iteration: 55; Mean diff: 0.0001\n",
      "Iteration: 56; Mean diff: 0.0001\n",
      "Iteration: 57; Mean diff: 0.0001\n",
      "Iteration: 58; Mean diff: 0.0001\n",
      "Iteration: 59; Mean diff: 0.0001\n",
      "Iteration: 60; Mean diff: 0.0001\n",
      "Iteration: 61; Mean diff: 0.0000\n",
      "Iteration: 62; Mean diff: 0.0000\n",
      "Iteration: 63; Mean diff: 0.0000\n",
      "Iteration: 64; Mean diff: 0.0000\n",
      "Iteration: 65; Mean diff: 0.0000\n",
      "Iteration: 66; Mean diff: 0.0000\n",
      "Iteration: 67; Mean diff: 0.0000\n",
      "Iteration: 68; Mean diff: 0.0000\n",
      "Iteration: 69; Mean diff: 0.0000\n",
      "Iteration: 70; Mean diff: 0.0000\n",
      "Iteration: 71; Mean diff: 0.0000\n",
      "Iteration: 72; Mean diff: 0.0000\n",
      "Iteration: 73; Mean diff: 0.0000\n",
      "Iteration: 74; Mean diff: 0.0000\n",
      "Iteration: 75; Mean diff: 0.0000\n",
      "Iteration: 76; Mean diff: 0.0000\n",
      "Iteration: 77; Mean diff: 0.0000\n",
      "Iteration: 78; Mean diff: 0.0000\n",
      "Iteration: 79; Mean diff: 0.0000\n",
      "Iteration: 80; Mean diff: 0.0000\n",
      "Iteration: 81; Mean diff: 0.0000\n",
      "Iteration: 82; Mean diff: 0.0000\n",
      "Iteration: 83; Mean diff: 0.0000\n",
      "Iteration: 84; Mean diff: 0.0000\n",
      "Iteration: 85; Mean diff: 0.0000\n",
      "Iteration: 86; Mean diff: 0.0000\n",
      "Iteration: 87; Mean diff: 0.0000\n",
      "Iteration: 88; Mean diff: 0.0000\n",
      "Iteration: 89; Mean diff: 0.0000\n",
      "Iteration: 90; Mean diff: 0.0000\n",
      "Iteration: 91; Mean diff: 0.0000\n",
      "Iteration: 92; Mean diff: 0.0000\n",
      "Iteration: 93; Mean diff: 0.0000\n",
      "Iteration: 94; Mean diff: 0.0000\n",
      "Iteration: 95; Mean diff: 0.0000\n",
      "Iteration: 96; Mean diff: 0.0000\n",
      "Iteration: 97; Mean diff: 0.0000\n",
      "Iteration: 98; Mean diff: 0.0000\n",
      "Iteration: 99; Mean diff: 0.0000\n",
      "Iteration: 100; Mean diff: 0.0000\n",
      "Iteration: 101; Mean diff: 0.0000\n",
      "Iteration: 102; Mean diff: 0.0000\n",
      "Iteration: 103; Mean diff: 0.0000\n",
      "Iteration: 104; Mean diff: 0.0000\n",
      "Iteration: 105; Mean diff: 0.0000\n",
      "Iteration: 106; Mean diff: 0.0000\n",
      "Iteration: 107; Mean diff: 0.0000\n",
      "Iteration: 108; Mean diff: 0.0000\n",
      "Iteration: 109; Mean diff: 0.0000\n",
      "Iteration: 110; Mean diff: 0.0000\n",
      "Iteration: 111; Mean diff: 0.0000\n",
      "Iteration: 112; Mean diff: 0.0000\n",
      "Stopping criteria met, training terminated.\n",
      "Done training!\n",
      "\n",
      "Computing conformal prediction intervals for 100 test queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CI: 100%|████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing conformal prediction intervals for 100 test queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CI: 100%|████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "k:  67%|█████████████████████████████████████████████████████▎                          | 2/3 [07:05<03:36, 216.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating missingness with guessed rank 5...\n",
      "iter: 1\n",
      "iter: 2\n",
      "iter: 3\n",
      "iter: 4\n",
      "iter: 5\n",
      "iter: 6\n",
      "iter: 7\n",
      "iter: 8\n",
      "iter: 9\n",
      "iter: 10\n",
      "iter: 11\n",
      "iter: 12\n",
      "iter: 13\n",
      "iter: 14\n",
      "Function value changing by less than progTol\n",
      "Done estimating!\n",
      "\n",
      "Training size:32000, calib size: 2000, test size: 100\n",
      "\n",
      "Running matrix completion algorithm on the splitted training set...\n",
      "Iteration: 1; Mean diff: 0.0074\n",
      "Iteration: 2; Mean diff: 0.0055\n",
      "Iteration: 3; Mean diff: 0.0039\n",
      "Iteration: 4; Mean diff: 0.0014\n",
      "Iteration: 5; Mean diff: 0.0009\n",
      "Iteration: 6; Mean diff: 0.0005\n",
      "Iteration: 7; Mean diff: 0.0004\n",
      "Iteration: 8; Mean diff: 0.0003\n",
      "Iteration: 9; Mean diff: 0.0003\n",
      "Iteration: 10; Mean diff: 0.0002\n",
      "Iteration: 11; Mean diff: 0.0002\n",
      "Iteration: 12; Mean diff: 0.0002\n",
      "Iteration: 13; Mean diff: 0.0002\n",
      "Iteration: 14; Mean diff: 0.0001\n",
      "Iteration: 15; Mean diff: 0.0001\n",
      "Iteration: 16; Mean diff: 0.0001\n",
      "Iteration: 17; Mean diff: 0.0001\n",
      "Iteration: 18; Mean diff: 0.0001\n",
      "Iteration: 19; Mean diff: 0.0001\n",
      "Iteration: 20; Mean diff: 0.0001\n",
      "Iteration: 21; Mean diff: 0.0001\n",
      "Iteration: 22; Mean diff: 0.0001\n",
      "Iteration: 23; Mean diff: 0.0001\n",
      "Iteration: 24; Mean diff: 0.0001\n",
      "Iteration: 25; Mean diff: 0.0001\n",
      "Iteration: 26; Mean diff: 0.0001\n",
      "Iteration: 27; Mean diff: 0.0001\n",
      "Iteration: 28; Mean diff: 0.0002\n",
      "Iteration: 29; Mean diff: 0.0002\n",
      "Iteration: 30; Mean diff: 0.0002\n",
      "Iteration: 31; Mean diff: 0.0002\n",
      "Iteration: 32; Mean diff: 0.0002\n",
      "Iteration: 33; Mean diff: 0.0003\n",
      "Iteration: 34; Mean diff: 0.0003\n",
      "Iteration: 35; Mean diff: 0.0003\n",
      "Iteration: 36; Mean diff: 0.0003\n",
      "Iteration: 37; Mean diff: 0.0003\n",
      "Iteration: 38; Mean diff: 0.0003\n",
      "Iteration: 39; Mean diff: 0.0002\n",
      "Iteration: 40; Mean diff: 0.0002\n",
      "Iteration: 41; Mean diff: 0.0002\n",
      "Iteration: 42; Mean diff: 0.0002\n",
      "Iteration: 43; Mean diff: 0.0002\n",
      "Iteration: 44; Mean diff: 0.0002\n",
      "Iteration: 45; Mean diff: 0.0001\n",
      "Iteration: 46; Mean diff: 0.0001\n",
      "Iteration: 47; Mean diff: 0.0001\n",
      "Iteration: 48; Mean diff: 0.0001\n",
      "Iteration: 49; Mean diff: 0.0001\n",
      "Iteration: 50; Mean diff: 0.0001\n",
      "Iteration: 51; Mean diff: 0.0001\n",
      "Iteration: 52; Mean diff: 0.0001\n",
      "Iteration: 53; Mean diff: 0.0001\n",
      "Iteration: 54; Mean diff: 0.0001\n",
      "Iteration: 55; Mean diff: 0.0001\n",
      "Iteration: 56; Mean diff: 0.0001\n",
      "Iteration: 57; Mean diff: 0.0001\n",
      "Iteration: 58; Mean diff: 0.0000\n",
      "Iteration: 59; Mean diff: 0.0000\n",
      "Iteration: 60; Mean diff: 0.0000\n",
      "Iteration: 61; Mean diff: 0.0000\n",
      "Iteration: 62; Mean diff: 0.0000\n",
      "Iteration: 63; Mean diff: 0.0000\n",
      "Iteration: 64; Mean diff: 0.0000\n",
      "Iteration: 65; Mean diff: 0.0000\n",
      "Iteration: 66; Mean diff: 0.0000\n",
      "Iteration: 67; Mean diff: 0.0000\n",
      "Iteration: 68; Mean diff: 0.0000\n",
      "Iteration: 69; Mean diff: 0.0000\n",
      "Iteration: 70; Mean diff: 0.0000\n",
      "Iteration: 71; Mean diff: 0.0000\n",
      "Iteration: 72; Mean diff: 0.0000\n",
      "Iteration: 73; Mean diff: 0.0000\n",
      "Iteration: 74; Mean diff: 0.0000\n",
      "Iteration: 75; Mean diff: 0.0000\n",
      "Iteration: 76; Mean diff: 0.0000\n",
      "Iteration: 77; Mean diff: 0.0000\n",
      "Iteration: 78; Mean diff: 0.0000\n",
      "Iteration: 79; Mean diff: 0.0000\n",
      "Iteration: 80; Mean diff: 0.0000\n",
      "Iteration: 81; Mean diff: 0.0000\n",
      "Iteration: 82; Mean diff: 0.0000\n",
      "Iteration: 83; Mean diff: 0.0000\n",
      "Iteration: 84; Mean diff: 0.0000\n",
      "Iteration: 85; Mean diff: 0.0000\n",
      "Iteration: 86; Mean diff: 0.0000\n",
      "Iteration: 87; Mean diff: 0.0000\n",
      "Iteration: 88; Mean diff: 0.0000\n",
      "Iteration: 89; Mean diff: 0.0000\n",
      "Iteration: 90; Mean diff: 0.0000\n",
      "Iteration: 91; Mean diff: 0.0000\n",
      "Iteration: 92; Mean diff: 0.0000\n",
      "Iteration: 93; Mean diff: 0.0000\n",
      "Iteration: 94; Mean diff: 0.0000\n",
      "Iteration: 95; Mean diff: 0.0000\n",
      "Iteration: 96; Mean diff: 0.0000\n",
      "Iteration: 97; Mean diff: 0.0000\n",
      "Iteration: 98; Mean diff: 0.0000\n",
      "Iteration: 99; Mean diff: 0.0000\n",
      "Iteration: 100; Mean diff: 0.0000\n",
      "Iteration: 101; Mean diff: 0.0000\n",
      "Stopping criteria met, training terminated.\n",
      "Done training!\n",
      "\n",
      "Computing conformal prediction intervals for 100 test queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CI: 100%|████████████████████████████████████████████████████████████████████████████| 100/100 [00:11<00:00,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Computing conformal prediction intervals for 100 test queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CI: 100%|████████████████████████████████████████████████████████████████████████████| 100/100 [00:11<00:00,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "k: 100%|████████████████████████████████████████████████████████████████████████████████| 3/3 [10:15<00:00, 205.24s/it]\n",
      "Repetitions: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [10:15<00:00, 615.74s/it]\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "#  Run Experiments  #\n",
    "#####################\n",
    "results = pd.DataFrame({})\n",
    "\n",
    "for i in tqdm(range(1, repetition+1), desc=\"Repetitions\", leave=True, position=0):\n",
    "    random_state = repetition * (seed-1) + i\n",
    "    \n",
    "    for k in tqdm(k_list, desc=\"k\", leave=True, position=0):\n",
    "\n",
    "        res = run_single_experiment(M, k, alpha, prop_obs, max_test_queries, max_calib_queries,\n",
    "                            r, scale=scale, random_state=random_state)\n",
    "        \n",
    "        results = pd.concat([results, res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f55d08f0-2560-4d9d-8c9f-df35a51b6cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query_coverage</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Size</th>\n",
       "      <th>Inf_prop</th>\n",
       "      <th>Method</th>\n",
       "      <th>k</th>\n",
       "      <th>avg_gap</th>\n",
       "      <th>Calib_queries</th>\n",
       "      <th>Train_entries</th>\n",
       "      <th>Test_queries</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>7.197203</td>\n",
       "      <td>0.01</td>\n",
       "      <td>conformal</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>2000</td>\n",
       "      <td>44000</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>6.980278</td>\n",
       "      <td>0.00</td>\n",
       "      <td>est</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>2000</td>\n",
       "      <td>44000</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>8.753994</td>\n",
       "      <td>0.02</td>\n",
       "      <td>conformal</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>2000</td>\n",
       "      <td>38000</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>8.398095</td>\n",
       "      <td>0.00</td>\n",
       "      <td>est</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>2000</td>\n",
       "      <td>38000</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>10.555317</td>\n",
       "      <td>0.06</td>\n",
       "      <td>conformal</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>2000</td>\n",
       "      <td>32000</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.9675</td>\n",
       "      <td>9.474108</td>\n",
       "      <td>0.00</td>\n",
       "      <td>est</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>2000</td>\n",
       "      <td>32000</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Query_coverage  Coverage       Size  Inf_prop     Method  k   avg_gap  \\\n",
       "0            0.88    0.9400   7.197203      0.01  conformal  2  0.000130   \n",
       "0            0.88    0.9400   6.980278      0.00        est  2  0.000130   \n",
       "0            0.86    0.9680   8.753994      0.02  conformal  5  0.000225   \n",
       "0            0.85    0.9640   8.398095      0.00        est  5  0.000225   \n",
       "0            0.84    0.9775  10.555317      0.06  conformal  8  0.000293   \n",
       "0            0.78    0.9675   9.474108      0.00        est  8  0.000293   \n",
       "\n",
       "   Calib_queries  Train_entries  Test_queries  random_state  \n",
       "0           2000          44000           100             1  \n",
       "0           2000          44000           100             1  \n",
       "0           2000          38000           100             1  \n",
       "0           2000          38000           100             1  \n",
       "0           2000          32000           100             1  \n",
       "0           2000          32000           100             1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d92812b-6e5e-4df4-be62-2d572db84c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
